{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNZlhW+tY1YyNnJOgMcXMS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyunini/DeepLearning_From_Scratch/blob/main/%EB%B0%91%EC%8B%9C%EB%94%A5ch08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VjWssUbSzNR",
        "outputId": "18842723-c041-453e-b42d-bb9b873b7eec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/2023_AI')\n",
        "sys.path.extend(\"./\")\n",
        "from mnist import load_mnist"
      ],
      "metadata": {
        "id": "AKL3Kj8aS0zG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요 함수, 클래스들"
      ],
      "metadata": {
        "id": "hThB1eOeUmrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def identity_function(x):\n",
        "    return x\n",
        "\n",
        "\n",
        "def step_function(x):\n",
        "    return np.array(x > 0, dtype=np.int)\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def sigmoid_grad(x):\n",
        "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "\n",
        "def relu_grad(x):\n",
        "    grad = np.zeros(x)\n",
        "    grad[x>=0] = 1\n",
        "    return grad\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T\n",
        "\n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "\n",
        "def mean_squared_error(y, t):\n",
        "    return 0.5 * np.sum((y-t)**2)\n",
        "\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "\n",
        "\n",
        "def softmax_loss(X, t):\n",
        "    y = softmax(X)\n",
        "    return cross_entropy_error(y, t)"
      ],
      "metadata": {
        "id": "RXi2Pfg0TtX8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def smooth_curve(x):\n",
        "    \"\"\"손실 함수의 그래프를 매끄럽게 하기 위해 사용\n",
        "\n",
        "    참고：http://glowingpython.blogspot.jp/2012/02/convolution-with-numpy.html\n",
        "    \"\"\"\n",
        "    window_len = 11\n",
        "    s = np.r_[x[window_len-1:0:-1], x, x[-1:-window_len:-1]]\n",
        "    w = np.kaiser(window_len, 2)\n",
        "    y = np.convolve(w/w.sum(), s, mode='valid')\n",
        "    return y[5:len(y)-5]\n",
        "\n",
        "\n",
        "def shuffle_dataset(x, t):\n",
        "    \"\"\"데이터셋을 뒤섞는다.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : 훈련 데이터\n",
        "    t : 정답 레이블\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x, t : 뒤섞은 훈련 데이터와 정답 레이블\n",
        "    \"\"\"\n",
        "    permutation = np.random.permutation(x.shape[0])\n",
        "    x = x[permutation,:] if x.ndim == 2 else x[permutation,:,:,:]\n",
        "    t = t[permutation]\n",
        "\n",
        "    return x, t\n",
        "\n",
        "def conv_output_size(input_size, filter_size, stride=1, pad=0):\n",
        "    return (input_size + 2*pad - filter_size) / stride + 1\n",
        "\n",
        "\n",
        "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
        "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
        "    filter_h : 필터의 높이\n",
        "    filter_w : 필터의 너비\n",
        "    stride : 스트라이드\n",
        "    pad : 패딩\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    col : 2차원 배열\n",
        "    \"\"\"\n",
        "    N, C, H, W = input_data.shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
        "\n",
        "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
        "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
        "\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
        "\n",
        "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
        "    return col\n",
        "\n",
        "\n",
        "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
        "    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    col : 2차원 배열(입력 데이터)\n",
        "    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）\n",
        "    filter_h : 필터의 높이\n",
        "    filter_w : 필터의 너비\n",
        "    stride : 스트라이드\n",
        "    pad : 패딩\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    img : 변환된 이미지들\n",
        "    \"\"\"\n",
        "    N, C, H, W = input_shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
        "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
        "\n",
        "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
        "\n",
        "    return img[:, :, pad:H + pad, pad:W + pad]"
      ],
      "metadata": {
        "id": "wiAcDeSqTzMF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = sigmoid(x)\n",
        "        self.out = out\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "\n",
        "        self.x = None\n",
        "        self.original_x_shape = None\n",
        "        # 가중치와 편향 매개변수의 미분\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 텐서 대응\n",
        "        self.original_x_shape = x.shape\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        self.x = x\n",
        "\n",
        "        out = np.dot(self.x, self.W) + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "\n",
        "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
        "        return dx\n",
        "\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None # 손실함수\n",
        "        self.y = None    # softmax의 출력\n",
        "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "        self.loss = cross_entropy_error(self.y, self.t)\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때\n",
        "            dx = (self.y - self.t) / batch_size\n",
        "        else:\n",
        "            dx = self.y.copy()\n",
        "            dx[np.arange(batch_size), self.t] -= 1\n",
        "            dx = dx / batch_size\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Dropout:\n",
        "    \"\"\"\n",
        "    http://arxiv.org/abs/1207.0580\n",
        "    \"\"\"\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x, train_flg=True):\n",
        "        if train_flg:\n",
        "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask\n",
        "\n",
        "\n",
        "class BatchNormalization:\n",
        "    \"\"\"\n",
        "    http://arxiv.org/abs/1502.03167\n",
        "    \"\"\"\n",
        "    def __init__(self, gamma, beta, momentum=0.9, running_mean=None, running_var=None):\n",
        "        self.gamma = gamma\n",
        "        self.beta = beta\n",
        "        self.momentum = momentum\n",
        "        self.input_shape = None # 합성곱 계층은 4차원, 완전연결 계층은 2차원\n",
        "\n",
        "        # 시험할 때 사용할 평균과 분산\n",
        "        self.running_mean = running_mean\n",
        "        self.running_var = running_var\n",
        "\n",
        "        # backward 시에 사용할 중간 데이터\n",
        "        self.batch_size = None\n",
        "        self.xc = None\n",
        "        self.std = None\n",
        "        self.dgamma = None\n",
        "        self.dbeta = None\n",
        "\n",
        "    def forward(self, x, train_flg=True):\n",
        "        self.input_shape = x.shape\n",
        "        if x.ndim != 2:\n",
        "            N, C, H, W = x.shape\n",
        "            x = x.reshape(N, -1)\n",
        "\n",
        "        out = self.__forward(x, train_flg)\n",
        "\n",
        "        return out.reshape(*self.input_shape)\n",
        "\n",
        "    def __forward(self, x, train_flg):\n",
        "        if self.running_mean is None:\n",
        "            N, D = x.shape\n",
        "            self.running_mean = np.zeros(D)\n",
        "            self.running_var = np.zeros(D)\n",
        "\n",
        "        if train_flg:\n",
        "            mu = x.mean(axis=0)\n",
        "            xc = x - mu\n",
        "            var = np.mean(xc**2, axis=0)\n",
        "            std = np.sqrt(var + 10e-7)\n",
        "            xn = xc / std\n",
        "\n",
        "            self.batch_size = x.shape[0]\n",
        "            self.xc = xc\n",
        "            self.xn = xn\n",
        "            self.std = std\n",
        "            self.running_mean = self.momentum * self.running_mean + (1-self.momentum) * mu\n",
        "            self.running_var = self.momentum * self.running_var + (1-self.momentum) * var\n",
        "        else:\n",
        "            xc = x - self.running_mean\n",
        "            xn = xc / ((np.sqrt(self.running_var + 10e-7)))\n",
        "\n",
        "        out = self.gamma * xn + self.beta\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        if dout.ndim != 2:\n",
        "            N, C, H, W = dout.shape\n",
        "            dout = dout.reshape(N, -1)\n",
        "\n",
        "        dx = self.__backward(dout)\n",
        "\n",
        "        dx = dx.reshape(*self.input_shape)\n",
        "        return dx\n",
        "\n",
        "    def __backward(self, dout):\n",
        "        dbeta = dout.sum(axis=0)\n",
        "        dgamma = np.sum(self.xn * dout, axis=0)\n",
        "        dxn = self.gamma * dout\n",
        "        dxc = dxn / self.std\n",
        "        dstd = -np.sum((dxn * self.xc) / (self.std * self.std), axis=0)\n",
        "        dvar = 0.5 * dstd / self.std\n",
        "        dxc += (2.0 / self.batch_size) * self.xc * dvar\n",
        "        dmu = np.sum(dxc, axis=0)\n",
        "        dx = dxc - dmu / self.batch_size\n",
        "\n",
        "        self.dgamma = dgamma\n",
        "        self.dbeta = dbeta\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Convolution:\n",
        "    def __init__(self, W, b, stride=1, pad=0):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "        # 중간 데이터（backward 시 사용）\n",
        "        self.x = None\n",
        "        self.col = None\n",
        "        self.col_W = None\n",
        "\n",
        "        # 가중치와 편향 매개변수의 기울기\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
        "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
        "\n",
        "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
        "        col_W = self.W.reshape(FN, -1).T\n",
        "\n",
        "        out = np.dot(col, col_W) + self.b\n",
        "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
        "\n",
        "        self.x = x\n",
        "        self.col = col\n",
        "        self.col_W = col_W\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
        "\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "        self.dW = np.dot(self.col.T, dout)\n",
        "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
        "\n",
        "        dcol = np.dot(dout, self.col_W.T)\n",
        "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Pooling:\n",
        "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
        "        self.pool_h = pool_h\n",
        "        self.pool_w = pool_w\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "        self.x = None\n",
        "        self.arg_max = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
        "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
        "\n",
        "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
        "\n",
        "        arg_max = np.argmax(col, axis=1)\n",
        "        out = np.max(col, axis=1)\n",
        "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
        "\n",
        "        self.x = x\n",
        "        self.arg_max = arg_max\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout = dout.transpose(0, 2, 3, 1)\n",
        "\n",
        "        pool_size = self.pool_h * self.pool_w\n",
        "        dmax = np.zeros((dout.size, pool_size))\n",
        "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
        "        dmax = dmax.reshape(dout.shape + (pool_size,))\n",
        "\n",
        "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
        "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "qQlltIx6ToqI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 깊게 쌓은 ConvNet"
      ],
      "metadata": {
        "id": "rINptUu2UqZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zdnSNf5uRIMu"
      },
      "outputs": [],
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class DeepConvNet:\n",
        "    \"\"\"정확도 99% 이상의 고정밀 합성곱 신경망\n",
        "\n",
        "    네트워크 구성은 아래와 같음\n",
        "        conv - relu - conv- relu - pool -\n",
        "        conv - relu - conv- relu - pool -\n",
        "        conv - relu - conv- relu - pool -\n",
        "        affine - relu - dropout - affine - dropout - softmax\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=(1, 28, 28),\n",
        "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n",
        "                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 hidden_size=50, output_size=10):\n",
        "        # 가중치 초기화===========\n",
        "        # 각 층의 뉴런 하나당 앞 층의 몇 개 뉴런과 연결되는가（TODO: 자동 계산되게 바꿀 것）\n",
        "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
        "        wight_init_scales = np.sqrt(2.0 / pre_node_nums)  # ReLU를 사용할 때의 권장 초깃값\n",
        "\n",
        "        self.params = {}\n",
        "        pre_channel_num = input_dim[0]\n",
        "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
        "            self.params['W' + str(idx+1)] = wight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
        "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
        "            pre_channel_num = conv_param['filter_num']\n",
        "        self.params['W7'] = wight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
        "        self.params['b7'] = np.zeros(hidden_size)\n",
        "        self.params['W8'] = wight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b8'] = np.zeros(output_size)\n",
        "\n",
        "        # 계층 생성===========\n",
        "        self.layers = []\n",
        "        self.layers.append(Convolution(self.params['W1'], self.params['b1'],\n",
        "                           conv_param_1['stride'], conv_param_1['pad']))\n",
        "        self.layers.append(Relu())\n",
        "        self.layers.append(Convolution(self.params['W2'], self.params['b2'],\n",
        "                           conv_param_2['stride'], conv_param_2['pad']))\n",
        "        self.layers.append(Relu())\n",
        "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
        "        self.layers.append(Convolution(self.params['W3'], self.params['b3'],\n",
        "                           conv_param_3['stride'], conv_param_3['pad']))\n",
        "        self.layers.append(Relu())\n",
        "        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n",
        "                           conv_param_4['stride'], conv_param_4['pad']))\n",
        "        self.layers.append(Relu())\n",
        "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
        "        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n",
        "                           conv_param_5['stride'], conv_param_5['pad']))\n",
        "        self.layers.append(Relu())\n",
        "        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n",
        "                           conv_param_6['stride'], conv_param_6['pad']))\n",
        "        self.layers.append(Relu())\n",
        "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
        "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
        "        self.layers.append(Relu())\n",
        "        self.layers.append(Dropout(0.5))\n",
        "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
        "        self.layers.append(Dropout(0.5))\n",
        "\n",
        "        self.last_layer = SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self, x, train_flg=False):\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, Dropout):\n",
        "                x = layer.forward(x, train_flg)\n",
        "            else:\n",
        "                x = layer.forward(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x, train_flg=True)\n",
        "        return self.last_layer.forward(y, t)\n",
        "\n",
        "    def accuracy(self, x, t, batch_size=100):\n",
        "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
        "\n",
        "        acc = 0.0\n",
        "\n",
        "        for i in range(int(x.shape[0] / batch_size)):\n",
        "            tx = x[i*batch_size:(i+1)*batch_size]\n",
        "            tt = t[i*batch_size:(i+1)*batch_size]\n",
        "            y = self.predict(tx, train_flg=False)\n",
        "            y = np.argmax(y, axis=1)\n",
        "            acc += np.sum(y == tt)\n",
        "\n",
        "        return acc / x.shape[0]\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.last_layer.backward(dout)\n",
        "\n",
        "        tmp_layers = self.layers.copy()\n",
        "        tmp_layers.reverse()\n",
        "        for layer in tmp_layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 결과 저장\n",
        "        grads = {}\n",
        "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
        "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
        "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def save_params(self, file_name=\"params.pkl\"):\n",
        "        params = {}\n",
        "        for key, val in self.params.items():\n",
        "            params[key] = val\n",
        "        with open(file_name, 'wb') as f:\n",
        "            pickle.dump(params, f)\n",
        "\n",
        "    def load_params(self, file_name=\"params.pkl\"):\n",
        "        with open(file_name, 'rb') as f:\n",
        "            params = pickle.load(f)\n",
        "        for key, val in params.items():\n",
        "            self.params[key] = val\n",
        "\n",
        "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
        "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
        "            self.layers[layer_idx].b = self.params['b' + str(i+1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 반정밀도 - 16비트 사용"
      ],
      "metadata": {
        "id": "iIOBqgKhbP9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mnist import load_mnist\n",
        "\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
        "\n",
        "network = DeepConvNet()\n",
        "network.load_params(\"deep_convnet_params.pkl\")\n",
        "\n",
        "sampled = 10000 # 고속화를 위한 표본추출\n",
        "x_test = x_test[:sampled]\n",
        "t_test = t_test[:sampled]\n",
        "\n",
        "print(\"caluculate accuracy (float64) ... \")\n",
        "print(network.accuracy(x_test, t_test))\n",
        "\n",
        "# float16(반정밀도)로 형변환\n",
        "x_test = x_test.astype(np.float16)\n",
        "for param in network.params.values():\n",
        "    param[...] = param.astype(np.float16)\n",
        "\n",
        "print(\"caluculate accuracy (float16) ... \")\n",
        "print(network.accuracy(x_test, t_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7bN76G2RXNb",
        "outputId": "74bbf240-9429-40a3-a646-327f5ca3c7e0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caluculate accuracy (float64) ... \n",
            "0.9935\n",
            "caluculate accuracy (float16) ... \n",
            "0.9935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mnist import load_mnist\n",
        "\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
        "\n",
        "network = DeepConvNet()\n",
        "network.load_params(\"deep_convnet_params.pkl\")\n",
        "\n",
        "print(\"calculating test accuracy ... \")\n",
        "#sampled = 1000\n",
        "#x_test = x_test[:sampled]\n",
        "#t_test = t_test[:sampled]\n",
        "\n",
        "classified_ids = []\n",
        "\n",
        "acc = 0.0\n",
        "batch_size = 100\n",
        "\n",
        "for i in range(int(x_test.shape[0] / batch_size)):\n",
        "    tx = x_test[i*batch_size:(i+1)*batch_size]\n",
        "    tt = t_test[i*batch_size:(i+1)*batch_size]\n",
        "    y = network.predict(tx, train_flg=False)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    classified_ids.append(y)\n",
        "    acc += np.sum(y == tt)\n",
        "\n",
        "acc = acc / x_test.shape[0]\n",
        "print(\"test accuracy:\" + str(acc))\n",
        "\n",
        "classified_ids = np.array(classified_ids)\n",
        "classified_ids = classified_ids.flatten()\n",
        "\n",
        "max_view = 20\n",
        "current_view = 1\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.2, wspace=0.2)\n",
        "\n",
        "mis_pairs = {}\n",
        "for i, val in enumerate(classified_ids == t_test):\n",
        "    if not val:\n",
        "        ax = fig.add_subplot(4, 5, current_view, xticks=[], yticks=[])\n",
        "        ax.imshow(x_test[i].reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "        mis_pairs[current_view] = (t_test[i], classified_ids[i])\n",
        "\n",
        "        current_view += 1\n",
        "        if current_view > max_view:\n",
        "            break\n",
        "\n",
        "print(\"======= misclassified result =======\")\n",
        "print(\"{view index: (label, inference), ...}\")\n",
        "print(mis_pairs)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "_1nwkGS5RfzL",
        "outputId": "5feb51c2-9867-4121-ee5d-fc9adcec0426"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating test accuracy ... \n",
            "test accuracy:0.9935\n",
            "======= misclassified result =======\n",
            "{view index: (label, inference), ...}\n",
            "{1: (6, 0), 2: (3, 5), 3: (3, 5), 4: (8, 3), 5: (7, 3), 6: (1, 3), 7: (8, 9), 8: (6, 0), 9: (6, 5), 10: (7, 2), 11: (9, 4), 12: (7, 1), 13: (5, 3), 14: (1, 3), 15: (0, 6), 16: (9, 4), 17: (7, 9), 18: (6, 0), 19: (9, 8), 20: (4, 9)}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 직접 학습하기"
      ],
      "metadata": {
        "id": "NuwJiyEFUiZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "import numpy as np\n",
        "\n",
        "class SGD:\n",
        "\n",
        "    \"\"\"확률적 경사 하강법（Stochastic Gradient Descent）\"\"\"\n",
        "\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        for key in params.keys():\n",
        "            params[key] -= self.lr * grads[key]\n",
        "\n",
        "class Trainer:\n",
        "    \"\"\"신경망 훈련을 대신 해주는 클래스\n",
        "    \"\"\"\n",
        "    def __init__(self, network, x_train, t_train, x_test, t_test,\n",
        "                 epochs=20, mini_batch_size=100,\n",
        "                 optimizer='SGD', optimizer_param={'lr':0.01},\n",
        "                 evaluate_sample_num_per_epoch=None, verbose=True):\n",
        "        self.network = network\n",
        "        self.verbose = verbose\n",
        "        self.x_train = x_train\n",
        "        self.t_train = t_train\n",
        "        self.x_test = x_test\n",
        "        self.t_test = t_test\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = mini_batch_size\n",
        "        self.evaluate_sample_num_per_epoch = evaluate_sample_num_per_epoch\n",
        "\n",
        "        # optimzer\n",
        "        optimizer_class_dict = {'sgd':SGD}\n",
        "        self.optimizer = optimizer_class_dict[optimizer.lower()](**optimizer_param)\n",
        "\n",
        "        self.train_size = x_train.shape[0]\n",
        "        self.iter_per_epoch = max(self.train_size / mini_batch_size, 1)\n",
        "        self.max_iter = int(epochs * self.iter_per_epoch)\n",
        "        self.current_iter = 0\n",
        "        self.current_epoch = 0\n",
        "\n",
        "        self.train_loss_list = []\n",
        "        self.train_acc_list = []\n",
        "        self.test_acc_list = []\n",
        "\n",
        "    def train_step(self):\n",
        "        batch_mask = np.random.choice(self.train_size, self.batch_size)\n",
        "        x_batch = self.x_train[batch_mask]\n",
        "        t_batch = self.t_train[batch_mask]\n",
        "\n",
        "        grads = self.network.gradient(x_batch, t_batch)\n",
        "        self.optimizer.update(self.network.params, grads)\n",
        "\n",
        "        loss = self.network.loss(x_batch, t_batch)\n",
        "        self.train_loss_list.append(loss)\n",
        "        if self.verbose: print(\"train loss:\" + str(loss))\n",
        "\n",
        "        if self.current_iter % self.iter_per_epoch == 0:\n",
        "            self.current_epoch += 1\n",
        "\n",
        "            x_train_sample, t_train_sample = self.x_train, self.t_train\n",
        "            x_test_sample, t_test_sample = self.x_test, self.t_test\n",
        "            if not self.evaluate_sample_num_per_epoch is None:\n",
        "                t = self.evaluate_sample_num_per_epoch\n",
        "                x_train_sample, t_train_sample = self.x_train[:t], self.t_train[:t]\n",
        "                x_test_sample, t_test_sample = self.x_test[:t], self.t_test[:t]\n",
        "\n",
        "            train_acc = self.network.accuracy(x_train_sample, t_train_sample)\n",
        "            test_acc = self.network.accuracy(x_test_sample, t_test_sample)\n",
        "            self.train_acc_list.append(train_acc)\n",
        "            self.test_acc_list.append(test_acc)\n",
        "\n",
        "            if self.verbose: print(\"=== epoch:\" + str(self.current_epoch) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc) + \" ===\")\n",
        "        self.current_iter += 1\n",
        "\n",
        "    def train(self):\n",
        "        for i in range(self.max_iter):\n",
        "            self.train_step()\n",
        "\n",
        "        test_acc = self.network.accuracy(self.x_test, self.t_test)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"=============== Final Test Accuracy ===============\")\n",
        "            print(\"test acc:\" + str(test_acc))\n"
      ],
      "metadata": {
        "id": "cSz_CAEtRoye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mnist import load_mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
        "\n",
        "network = DeepConvNet()\n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
        "                  epochs=20, mini_batch_size=100,\n",
        "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
        "                  evaluate_sample_num_per_epoch=1000)\n",
        "trainer.train()\n",
        "\n",
        "# 매개변수 보관\n",
        "network.save_params(\"deep_convnet_params.pkl\")\n",
        "print(\"Saved Network Parameters!\")"
      ],
      "metadata": {
        "id": "syxXILWtRjwm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}